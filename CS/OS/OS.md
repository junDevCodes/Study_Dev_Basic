# 💡 운영체제

## 1. 동기화와 교착 상태

### 1-1. 프로세스와 스레드

- **프로세스 (Process)**
  - **정의**: 실행 중인 프로그램 (어플리케이션 개념)
  - **특징**: **독립된 메모리 공간**을 할당받습니다.
  - **예시**: 웹 브라우저의 각 탭 (Chrome, Firefox 등)

- **스레드 (Thread)**
  - **정의**: 프로세스 내에서 실행되는 흐름의 단위 (함수 실행 흐름 개념)
  - **특징**: 같은 프로세스의 스레드들은 **메모리 공간을 공유**합니다.
  - **장점**: 메모리 효율성, 빠른 생성/통신

- **스레드의 대안들**
  1. **멀티프로세싱**: 여러 프로세스로 병렬 처리 (안전하지만 비효율적)
  2. **코루틴**: 협력적 멀티태스킹 (async/await)
  3. **이벤트 루프**: 단일 스레드 이벤트 기반 처리

### 1-2. 동기화 문제

- **왜 동기화가 필요한가?**
  - 스레드들이 메모리를 공유하므로 **동시 접근 시 문제 발생**
  - **Race Condition**: 실행 순서에 따라 결과가 달라지는 현상
  - **Data Inconsistency**: 예상과 다른 결과가 발생하는 현상

- **은행 계좌 예시 (문제 상황)**
  - 초기 잔액: 1000원
  - 스레드 A: 500원 출금 / 스레드 B: 300원 출금
  - **문제 발생 과정**:
    1. A가 잔액 1000원 확인
    2. B가 잔액 1000원 확인
    3. A가 500원 출금 → 잔액 500원
    4. B가 300원 출금 → 잔액 700원 (**잘못된 결과!**)
  - **올바른 결과는 200원**이어야 합니다.

### 1-3. 임계 구역 (Critical Section)

- **정의**
  - **공유 자원**에 접근하는 코드 부분
  - **한 번에 하나의 스레드만 실행**되어야 하는 구역

- **임계 구역 크기의 영향**
  - **너무 클 때**: 안전하지만 성능 저하 (병렬성 감소)
  - **너무 작을 때**: 성능은 좋지만 동기화 실패 가능성
  - **적정 크기**: **꼭 보호해야 하는 부분만 포함**해야 합니다.

### 1-4. 동기화 도구

- **뮤텍스 (Mutex - Mutual Exclusion)**
  - **정의**: 임계 구역에 **1명만 접근 허용**
  - **비유**: 화장실 1개 - 한 번에 1명만 사용 가능
  - **사용 시기**: **단 하나의 자원**을 보호할 때
  - **예시**: 은행 계좌 잔액, 파일 쓰기, 전역 변수 수정

- **세마포어 (Semaphore)**
  - **정의**: 임계 구역에 **N명까지 접근 허용**
  - **비유**: 화장실 3개 - 번호표로 관리, 한 번에 3명까지 가능
  - **사용 시기**: **제한된 개수의 동일한 자원**이 있을 때
  - **예시**: 데이터베이스 연결 풀 (최대 10개 연결), 온라인 게임 동접자 수 제한 (1000명), 주차장 (100대까지 주차 가능)

- **핵심 구분**
  - 자원 1개 + 동시 접근 불가 → **뮤텍스**
  - 자원 여러 개 또는 동시 접근 허용 → **세마포어**

### 1-5. Reader-Writer Problem

- **문제 상황**
  - **읽기(Read)**: 여러 명이 동시에 해도 안전 (데이터 변경 없음)
  - **쓰기(Write)**: 반드시 **1명만** 해야 함 (데이터 일관성)

- **쓰기에서 동시 접근이 위험한 이유**
  1. **같은 위치 동시 수정**: 여러 스레드가 동시에 같은 메모리 위치에 쓰기 작업을 하면, 데이터가 덮어씌워지거나 섞여서 **의미 없는 값**이 될 수 있습니다. (예: "안녕" + "하세요" → "안하녕세요")
  2. **데이터 일관성 파괴**: 파일 크기 정보 등 **연관된 메타데이터가 엉망**이 될 수 있습니다. 예를 들어, 파일 내용을 쓰는 도중에 다른 스레드가 파일 크기를 업데이트하면 불일치가 발생합니다.
  3. **읽는 중 쓰기 발생**: 한 스레드가 데이터를 읽는 도중에 다른 스레드가 그 데이터를 수정해버리면, 읽는 스레드는 **일부는 원본, 일부는 수정본을 읽게 되어 일관성 없는 데이터**를 얻게 됩니다.

- **해결 방법**
  - 단순 뮤텍스만 사용하면 읽기도 1명씩만 가능하여 비효율적입니다.
  - 읽기는 동시 허용, 쓰기는 독점하는 **특별한 알고리즘**이 필요합니다.

### 1-6. 스레드 안전 (Thread Safety)

- **정의**
  - 여러 스레드가 동시에 접근해도 **올바르게 동작하는 상태**

- **스레드 안전하지 않은 예시**
  ```c
  int counter = 0;
  void increment() {
      counter++; // 읽기 → 증가 → 쓰기 (3단계, 원자적이지 않음)
  }
  ```

- **스레드 안전하게 만드는 방법**
  1. **뮤텍스/락**: OS 수준에서 제어
  2. **원자적 연산**: CPU 하드웨어 수준에서 제어 (더 효율적)
  3. **불변 객체**: 변경 불가능한 객체 사용

- **원자적 연산의 장점**
  - 하드웨어(CPU)가 메모리 버스 락으로 직접 처리
  - OS 개입 없음 → 시스템 콜 오버헤드 없음
  - Lock-free 프로그래밍 가능

### 1-7. 교착상태 (Deadlock)

- **정의**
  - 두 개 이상의 프로세스가 서로가 가진 자원을 기다리며 **무한히 대기하는 상황**

- **창구 비유로 이해하기**
  - 고객1: A창구 점유 → B창구 대기
  - 고객2: B창구 점유 → A창구 대기
  - **결과**: 서로 무한 대기

### 1-8. 교착상태의 4가지 필요조건

- **모든 조건이 동시에 성립해야 교착상태 발생**
  1. **상호 배제 (Mutual Exclusion)**: 자원을 한 번에 하나의 프로세스만 사용 가능
  2. **점유와 대기 (Hold and Wait)**: 자원을 점유한 채로 다른 자원을 대기
  3. **비선점 (No Preemption)**: 다른 프로세스의 자원을 강제로 빼앗을 수 없음
  4. **순환 대기 (Circular Wait)**: 프로세스들이 순환 형태로 서로의 자원을 대기

### 1-9. 교착상태 해결 전략

#### 1-9-1. 예방 (Prevention)

- **철학**: "기능 제한해도 괜찮으니 교착상태만은 절대 안 돼!"
- **방법**: 4가지 조건 중 하나를 없애서 교착상태를 원천 차단합니다.
  - **최적 방법**: **순환 대기 예방** ⭐
    - 모든 자원에 번호를 매기고 오름차순으로만 자원 요청을 허용합니다.
    - **예시**: 모든 스레드가 mutex1 → mutex2 순서로만 요청
- **특징**:
  - **100% 안전**: 교착상태 절대 발생 안 함
  - **성능 희생**: 제약이 많아 비효율적
  - **보수적**: 실제로는 괜찮을 상황도 막음

#### 1-9-2. 회피 (Avoidance): 은행가 알고리즘

- **철학**: "모든 기능 다 쓰고 싶고, 교착상태도 안 일어나게 하고 싶어!"
- **핵심 아이디어**: 자원 요청을 받으면 **시뮬레이션으로 안전성 검사**를 합니다. 안전한 순서가 존재하면 승인하고, 없으면 거절합니다.
- **알고리즘 과정**:
  1. 요청을 가상으로 승인해 보기
  2. 모든 프로세스를 완료할 수 있는 순서 찾기
  3. 순서가 존재하면 실제 승인, 없으면 거절
- **예시 (은행 대출)**:
  - 보유 현금: 400만원
  - A: 200만원 보유, 최대 500만원 필요 (300 더 필요)
  - B: 300만원 보유, 최대 400만원 필요 (100 더 필요)
  - C: 100만원 보유, 최대 600만원 필요 (500 더 필요)
  - **안전한 순서**: B(100) → A(200) → C(500) 완료 가능
- **장단점**:
  - **장점**: 교착상태 100% 예방, 안전성 보장
  - **단점**: 보수적 판단, 계산 오버헤드

#### 1-9-3. 탐지와 회복 (Detection & Recovery)

- **철학**: "일단 다 돌려보고, 교착상태 생기면 그때 해결하지 뭐!"
- **탐지 방법**: **자원 할당 그래프**
  1. 각 프로세스의 자원 점유/대기 상황 조회
  2. 대기 그래프 구성
  3. 순환(Cycle) 탐지
  4. 순환이 있으면 교착상태
- **회복 방법**: **희생자 선택**
  - **선택 기준**: 낮은 우선순위, 시작한 지 얼마 안 된 프로세스, 적은 자원 사용량, 재시작 비용이 적은 프로세스 등을 고려합니다.
  - **복잡한 상황**: 점수 = 우선순위 × 2 + 진행률 × 1 + 자원량 × 1 (낮은 점수의 프로세스를 희생자로 선택)
- **특징**:
  - **낙관적**: 대부분 교착상태가 일어나지 않을 것으로 가정
  - **성능 좋음**: 평상시 제약 없음
  - **오버헤드**: 탐지 알고리즘 실행 비용
  - **복구 비용**: 프로세스 재시작 등의 비용

### 1-10. 전략별 비교표

| **구분** | **예방 (Prevention)** | **회피 (Avoidance)** | **탐지 및 회복 (Detection & Recovery)** |
|----------|----------------------|---------------------|---------------------------------------|
| **철학** | "사고 예방이 최고" | "둘 다 잡고 싶어" | "사고 나면 그때 처리" |
| **성능** | 평상시 제약 많음 | 매번 검사로 느림 | 평상시 자유로움 |
| **안전성** | 100% 안전 | 100% 안전 | 일시적 교착상태 발생 |
| **복잡성** | 설계 단계에서 복잡 | 알고리즘 복잡 | 런타임에서 복잡 |
| **적용 분야** | 중요한 시스템 | 중간 수준 시스템 | 일반적인 시스템 |

### 1-11. 실무 적용 가이드

- **언제 어떤 전략을 사용할까?**
  - **예방 사용**:
    - 병원 생명유지장치
    - 항공기 제어 시스템
    - 금융 거래 시스템 (핵심 부분)
  - **회피 사용**:
    - 중요한데 성능도 필요한 시스템
    - 데이터베이스 관리 시스템
    - 은행 ATM 시스템
  - **탐지 및 회복 사용**:
    - 웹 브라우저
    - 온라인 게임
    - 일반 데스크톱 애플리케이션
    - 채팅 앱, 소셜 미디어

### 1-12. 핵심 설계 원칙

1. **꼭 필요한 부분만 임계 구역으로 설정**
2. **자원의 특성에 따라 적절한 동기화 도구 선택**
3. **성능과 안전성의 균형 고려**
4. **교착상태 가능성을 사전에 분석하고 대비**
5. **시스템의 중요도에 따른 전략 선택**

- **동기화의 목적**:
  - **안전성**: Race Condition 방지
  - **효율성**: 불필요한 대기 최소화
  - **일관성**: 데이터 무결성 보장

## 2. CPU 스케줄링

CPU 스케줄링은 **Ready Queue**에 대기 중인 여러 프로세스 중 누구를 먼저 CPU로 보낼지 결정하는 운영체제의 핵심 기능입니다.

### 2-1. CPU 스케줄링 성능 지표

- **대기시간 (Waiting Time)**: 프로세스가 Ready Queue에서 CPU 할당을 기다린 총 시간
- **반환시간 (Turnaround Time)**: 프로세스가 도착해서 완료될 때까지 걸린 총 시간
- **응답시간 (Response Time)**: 프로세스가 도착해서 첫 실행까지 걸린 시간

### 2-2. CPU 스케줄링 기초 개념

- **CPU 버스트**: 프로세스가 CPU를 연속으로 사용하는 시간
- **I/O 버스트**: 프로세스가 입출력 작업을 수행하는 시간
- **프로세스 유형**:
  - **CPU 집약적 (CPU-bound)**: CPU 버스트가 길고, I/O 버스트가 짧은 프로세스 (예: 복잡한 수학 계산, 게임 엔진)
  - **I/O 집약적 (I/O-bound)**: CPU 버스트가 짧고, I/O 버스트가 길거나 빈번한 프로세스 (예: 채팅, 웹 브라우징, 텍스트 에디터)
    - **어려웠던 점**: I/O-bound 프로세스를 먼저 처리해야 전체 평균 대기시간이 줄어든다는 점을 이해하는 데 어려움이 있었습니다.
    - **이해를 도운 비유**: **도서관 예시** (두꺼운 책 읽는 사람 vs 5분 만에 책 빌리는 사람)를 통해 짧은 작업을 먼저 처리하는 것이 전체 효율에 좋다는 것을 이해했습니다.

- **스케줄링 큐 (Scheduling Queue)**:
  - **Ready Queue (준비 큐)**: CPU 사용을 기다리는 프로세스들의 줄
  - **Device Queue (장치 대기 큐)**: 각 I/O 장치(하드디스크, 키보드 등)의 작업을 기다리는 프로세스들의 줄
    - **어려웠던 점**: 준비 큐와 대기 큐의 역할 및 차이를 혼동했습니다.
    - **이해를 도운 비유**: **은행 예시** (대출 창구 앞 줄 = 준비 큐, 입금/출금 창구 앞 줄 = 장치 대기 큐)를 통해 CPU 대기열과 I/O 대기열이 별개임을 명확히 이해했습니다.

### 2-3. CPU 스케줄링 알고리즘

1. **FCFS (First Come First Served)**
   - **원리**: 먼저 온 순서대로 처리 (비선점)
   - **장점**: 구현 간단, 공평함, 기아 현상 없음
   - **단점**: Convoy Effect (긴 프로세스 뒤에 짧은 프로세스들이 오래 기다림), 평균 대기시간이 길어질 수 있음

2. **SJF (Shortest Job First)**
   - **원리**: 실행시간이 가장 짧은 프로세스부터 처리 (비선점)
   - **장점**: 최적의 평균 대기시간
   - **단점**: **기아 현상** 발생 가능 (짧은 프로세스가 계속 들어오면 긴 프로세스가 영원히 실행 안 됨), 실행시간을 미리 알기 어려움

3. **SRT (Shortest Remaining Time)**
   - **원리**: 남은 실행시간이 가장 짧은 프로세스부터 처리 (선점)
   - **SJF의 선점 버전**으로, 더 짧은 프로세스가 오면 현재 실행 중인 프로세스를 중단하고 교체합니다.
   - **장점**: SJF보다 더 나은 평균 대기시간, 응답성 향상
   - **단점**: 문맥 교환 오버헤드, 기아 현상 완전 해결 안 됨

4. **라운드 로빈 (Round Robin)**
   - **원리**: 모든 프로세스에게 **동일한 시간 할당량(Time Quantum)**을 공평하게 부여하며 번갈아 실행 (선점)
   - **장점**: 공평성, 기아 현상 없음, 응답시간 예측 가능
   - **단점**: 문맥 교환 오버헤드, 시간 할당량 설정이 어려움

5. **우선순위 스케줄링 (Priority Scheduling)**
   - **원리**: 우선순위가 높은 프로세스부터 처리 (선점/비선점 가능)
   - **장점**: 중요한 프로세스 우선 처리, 유연한 정책 적용
   - **단점**: **기아 현상** 발생 가능 (낮은 우선순위 프로세스가 영원히 못 실행될 수 있음), 우선순위 설정의 어려움
   - **해결책**: **에이징 (Aging)** 기법 (대기시간이 길어질수록 우선순위를 점진적으로 높여줌)

6. **다단계 큐 (Multi-Level Queue)**
   - **원리**: 프로세스를 여러 종류로 분류하여 각각 다른 큐에서 관리하고, 각 큐마다 다른 스케줄링 알고리즘을 적용합니다. (예: 시스템 큐 - 우선순위, 대화형 큐 - 라운드 로빈, 배치 큐 - FCFS)

7. **다단계 피드백 큐 (Multi-Level Feedback Queue)**
   - **원리**: 프로세스의 **실제 동작을 관찰**하여 적절한 큐로 **동적으로 이동**시킵니다.
   - **규칙**: 모든 새 프로세스는 높은 우선순위 큐에 들어가고, 시간 할당량을 다 쓰면 하위 큐로 강등되며, 시간 할당량 안에 끝나면 같은 큐를 유지합니다.
   - **장점**: 자동 분류, 적응적, 공평성
   - **단점**: 구현 복잡성, 오버헤드, 기아 현상 발생 가능

8. **리눅스 CPU 스케줄링 (CFS: Completely Fair Scheduler)**
   - **리눅스 커널의 주요 스케줄러**입니다.
   - **SCHED_NORMAL** 정책에서 사용되며, "모든 프로세스가 가중치에 비례하여 정확히 동일한 CPU 시간을 받도록 하자!"는 철학을 가집니다.
   - **가상 런타임 (Virtual Runtime)**: 각 프로세스가 실제로 사용한 CPU 시간을 기록하고, 이 값을 가중치에 따라 조정하여 모든 프로세스가 동일한 가상 시간으로 진행되는 것처럼 보이게 합니다. 가상 런타임이 가장 적은 프로세스를 먼저 실행합니다.
     - **어려웠던 점**: "모든 프로세스에게 동일한 시간을 주되 가중치를 고려한다"는 개념이 실제 시간과 가상 런타임의 차이 때문에 혼란스러웠습니다.
     - **이해를 도운 비유**: **피자 나누기 예시** (중요한 사람에게 더 많은 피자를 주되, 모두가 공평하게 먹었다고 느끼게 하는 것)를 통해 실제 CPU 시간은 가중치에 따라 차등 배분되지만, 가상 런타임은 모든 프로세스가 동일한 속도로 증가하도록 조정된다는 것을 이해했습니다.
   - **Red-Black Tree**: 가상 런타임 순으로 정렬된 이진 트리를 사용하여 가장 적은 가상 런타임을 가진 프로세스를 효율적으로 선택합니다.
   - **리눅스 스케줄링 정책 연결**:
     - **SCHED_FIFO**: FCFS 알고리즘 (실시간 프로세스용)
     - **SCHED_RR**: 라운드 로빈 알고리즘 (실시간 프로세스용)
     - **SCHED_NORMAL**: CFS 알고리즘 (일반 대화형 프로세스용)
     - **SCHED_BATCH**: CFS 기반 (배치 작업용, 처리량 최적화)
     - **SCHED_IDLE**: 우선순위 스케줄링 (가장 낮은 우선순위, 유휴 작업용)

## 3. 가상 메모리 관리

### 3-1. 물리주소와 논리주소

- **핵심 개념**
  - **논리주소(가상주소)**: 프로그램이 사용하는 가상의 메모리 주소
  - **물리주소**: RAM에서 실제 데이터가 저장된 위치
  - **MMU (Memory Management Unit)**: 논리주소를 물리주소로 변환하는 하드웨어

- **이해를 도운 아파트 비유**
  - 논리주소: 각 가족이 말하는 "우리 집 1층 거실"
  - 물리주소: 실제 아파트 "101호 거실", "205호 거실"
  - 각 가족(프로그램)은 같은 "1층"이라고 말하지만, 실제로는 완전히 다른 방

- **왜 분리하는가?**
  - **격리(Isolation)**: 각 프로그램이 서로 간섭하지 않음
  - **단순성**: 프로그램 개발이 쉬워짐 (다른 프로그램 위치 신경 안 써도 됨)
  - **유연성**: 프로그램을 메모리 어디에든 로드 가능

### 3-2. 스와핑 (Swapping)

- **문제 상황**
  - RAM: 4GB
  - 필요한 메모리: 6GB (크롬 2GB + VS Code 1GB + 게임 3GB)

- **해결책**: 스와핑
  - 당장 사용하지 않는 프로그램을 하드디스크에 저장했다가, 필요할 때 다시 메모리로 가져오기

- **이해를 도운 옷장 비유**
  - 옷장(RAM): 작지만 빠르게 접근 가능
  - 압축팩(하드디스크): 크지만 꺼내는 데 시간이 오래 걸림
  - 계절별로 안 입는 옷은 압축팩에 저장하고, 필요할 때 꺼내서 사용

- **스와핑 과정**
  - **스왑 아웃(Swap Out)**: 메모리 → 하드디스크
  - **스왑 인(Swap In)**: 하드디스크 → 메모리